from GAN_models.py import GAN, VAEGAN

# =============================== Load Dataset ============================= #

# Depending on what the data looks like, length/width/height should be adjusted
# Assuming all augmentation and pre-processing steps are done
# Training and testing splits remain the same

# length =
# width =
# height ='

# Normalize the data (not sure if necessary?)
# Split into training, validation, and test sets

# =============================== Initialize Model ============================= #
basic_model = GAN()
basic_model.train(x_train, epochs=, batch=, save=)

